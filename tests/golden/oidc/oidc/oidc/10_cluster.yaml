apiVersion: v1
kind: ServiceAccount
metadata:
  annotations: {}
  labels:
    name: vc-oidc
  name: vc-oidc
  namespace: testns
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
rules:
  - apiGroups:
      - ''
    resources:
      - configmaps
      - secrets
      - services
      - pods
      - pods/attach
      - pods/portforward
      - pods/exec
      - endpoints
      - persistentvolumeclaims
    verbs:
      - create
      - delete
      - patch
      - update
      - get
      - list
      - watch
  - apiGroups:
      - ''
    resources:
      - events
      - pods/log
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - create
      - delete
      - patch
      - update
      - get
      - list
      - watch
  - apiGroups:
      - apps
    resources:
      - statefulsets
      - replicasets
      - deployments
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: oidc
subjects:
  - kind: ServiceAccount
    name: vc-oidc
    namespace: testns
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations: {}
  labels:
    name: syn-vcluster-oidc
  name: syn-vcluster-oidc
rules:
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations: {}
  labels:
    name: syn-vcluster-oidc
  name: syn-vcluster-oidc
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: syn-vcluster-oidc
subjects:
  - kind: ServiceAccount
    name: vc-oidc
    namespace: testns
---
apiVersion: v1
kind: Service
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
  selector:
    app: vcluster
    release: oidc
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations: {}
  labels:
    name: oidc-headless
  name: oidc-headless
  namespace: testns
spec:
  clusterIP: None
  ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
  selector:
    app: vcluster
    release: oidc
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vcluster
      release: oidc
  serviceName: oidc-headless
  template:
    metadata:
      labels:
        app: vcluster
        release: oidc
    spec:
      affinity: {}
      containers:
        - args:
            - server
            - --write-kubeconfig=/data/k3s-config/kube-config.yaml
            - --data-dir=/data
            - --disable=traefik,servicelb,metrics-server,local-storage,coredns
            - --disable-network-policy
            - --disable-agent
            - --disable-scheduler
            - --disable-cloud-controller
            - --flannel-backend=none
            - --service-cidr=172.30.0.0/16
            - --kube-controller-manager-arg=controllers=*,-nodeipam,-nodelifecycle,-persistentvolume-binder,-attachdetach,-persistentvolume-expander,-cloud-node-lifecycle
            - --tls-san=oidc.testns.svc.cluster.local
            - --tls-san=oidc.testns.svc
            - --tls-san=oidc.testns
            - --tls-san=oidc
            - --kube-apiserver-arg=oidc-issuer-url=https://id.local/auth/realms/local
            - --kube-apiserver-arg=oidc-client-id=local
            - --kube-apiserver-arg=oidc-username-claim=email
            - --kube-apiserver-arg=oidc-groups-claim=groups
          command:
            - /bin/k3s
          env: []
          image: docker.io/rancher/k3s:v1.25.3-k3s1
          name: vcluster
          resources:
            limits:
              memory: 2Gi
            requests:
              cpu: 200m
              memory: 256Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
            - mountPath: /data
              name: data
            - mountPath: /etc/rancher
              name: etc-rancher
        - args:
            - --name=oidc
            - --out-kube-config-secret=vc-oidc-kubeconfig
            - --sync=ingresses
            - --tls-san=oidc.testns.svc.cluster.local
            - --tls-san=oidc.testns.svc
            - --tls-san=oidc.testns
            - --tls-san=oidc
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          image: docker.io/loftsh/vcluster:0.12.3
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /healthz
              port: 8443
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 2
          name: syncer
          readinessProbe:
            failureThreshold: 30
            httpGet:
              path: /readyz
              port: 8443
              scheme: HTTPS
            periodSeconds: 2
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
            - mountPath: /data
              name: data
              readOnly: true
            - mountPath: /manifests/coredns
              name: coredns
              readOnly: true
      nodeSelector: {}
      serviceAccountName: vc-oidc
      terminationGracePeriodSeconds: 10
      tolerations: []
      volumes:
        - configMap:
            defaultMode: 420
            name: vc-oidc-coredns
          name: coredns
        - emptyDir: {}
          name: etc-rancher
        - emptyDir: {}
          name: data
  volumeClaimTemplates: []
---
apiVersion: v1
data:
  manifests: "---\n\"apiVersion\": \"rbac.authorization.k8s.io/v1\"\n\"kind\": \"\
    ClusterRoleBinding\"\n\"metadata\":\n  \"name\": \"oidc-cluster-admin\"\n\"roleRef\"\
    :\n  \"apiGroup\": \"rbac.authorization.k8s.io\"\n  \"kind\": \"ClusterRole\"\n\
    \  \"name\": \"cluster-admin\"\n\"subjects\":\n- \"kind\": \"Group\"\n  \"name\"\
    : \"admin\"\n"
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    name: oidc-init-manifests
  name: oidc-init-manifests
  namespace: testns
---
apiVersion: v1
data:
  coredns.yaml: "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: coredns\n\
    \  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind:\
    \ ClusterRole\nmetadata:\n  labels:\n    kubernetes.io/bootstrapping: rbac-defaults\n\
    \  name: system:coredns\nrules:\n  - apiGroups:\n      - \"\"\n    resources:\n\
    \      - endpoints\n      - services\n      - pods\n      - namespaces\n    verbs:\n\
    \      - list\n      - watch\n  - apiGroups:\n      - discovery.k8s.io\n    resources:\n\
    \      - endpointslices\n    verbs:\n      - list\n      - watch\n---\napiVersion:\
    \ rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  annotations:\n\
    \    rbac.authorization.kubernetes.io/autoupdate: \"true\"\n  labels:\n    kubernetes.io/bootstrapping:\
    \ rbac-defaults\n  name: system:coredns\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n\
    \  kind: ClusterRole\n  name: system:coredns\nsubjects:\n  - kind: ServiceAccount\n\
    \    name: coredns\n    namespace: kube-system\n---\napiVersion: v1\nkind: ConfigMap\n\
    metadata:\n  name: coredns\n  namespace: kube-system\ndata:\n  Corefile: |\n \
    \   .:1053 {\n        {{.LOG_IN_DEBUG}}\n        errors\n        health\n    \
    \    ready\n        kubernetes cluster.local in-addr.arpa ip6.arpa {\n       \
    \   pods insecure\n          fallthrough in-addr.arpa ip6.arpa\n        }\n  \
    \      hosts /etc/coredns/NodeHosts {\n          ttl 60\n          reload 15s\n\
    \          fallthrough\n        }\n        prometheus :9153\n        forward .\
    \ /etc/resolv.conf\n        cache 30\n        loop\n        reload\n        loadbalance\n\
    \    }\n\n    import /etc/coredns/custom/*.server\n  NodeHosts: \"\"\n---\napiVersion:\
    \ apps/v1\nkind: Deployment\nmetadata:\n  name: coredns\n  namespace: kube-system\n\
    \  labels:\n    k8s-app: kube-dns\n    kubernetes.io/name: \"CoreDNS\"\nspec:\n\
    \  replicas: 1\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n   \
    \   maxUnavailable: 1\n  selector:\n    matchLabels:\n      k8s-app: kube-dns\n\
    \  template:\n    metadata:\n      labels:\n        k8s-app: kube-dns\n    spec:\n\
    \      priorityClassName: \"system-cluster-critical\"\n      serviceAccountName:\
    \ coredns\n      nodeSelector:\n        kubernetes.io/os: linux\n      topologySpreadConstraints:\n\
    \        - maxSkew: 1\n          topologyKey: kubernetes.io/hostname\n       \
    \   whenUnsatisfiable: DoNotSchedule\n          labelSelector:\n            matchLabels:\n\
    \              k8s-app: kube-dns\n      containers:\n        - name: coredns\n\
    \          image: {{.IMAGE}}\n          imagePullPolicy: IfNotPresent\n      \
    \    resources:\n            limits:\n              cpu: 1000m\n             \
    \ memory: 170Mi\n            requests:\n              cpu: 100m\n            \
    \  memory: 70Mi\n          args: [ \"-conf\", \"/etc/coredns/Corefile\" ]\n  \
    \        volumeMounts:\n            - name: config-volume\n              mountPath:\
    \ /etc/coredns\n              readOnly: true\n            - name: custom-config-volume\n\
    \              mountPath: /etc/coredns/custom\n              readOnly: true\n\
    \          ports:\n            - containerPort: 1053\n              name: dns\n\
    \              protocol: UDP\n            - containerPort: 1053\n            \
    \  name: dns-tcp\n              protocol: TCP\n            - containerPort: 9153\n\
    \              name: metrics\n              protocol: TCP\n          securityContext:\n\
    \            runAsUser: {{.RUN_AS_USER}}\n            runAsNonRoot: {{.RUN_AS_NON_ROOT}}\n\
    \            allowPrivilegeEscalation: false\n            capabilities:\n    \
    \          drop:\n                - ALL\n            readOnlyRootFilesystem: true\n\
    \          livenessProbe:\n            httpGet:\n              path: /health\n\
    \              port: 8080\n              scheme: HTTP\n            initialDelaySeconds:\
    \ 60\n            periodSeconds: 10\n            timeoutSeconds: 1\n         \
    \   successThreshold: 1\n            failureThreshold: 3\n          readinessProbe:\n\
    \            httpGet:\n              path: /ready\n              port: 8181\n\
    \              scheme: HTTP\n            initialDelaySeconds: 0\n            periodSeconds:\
    \ 2\n            timeoutSeconds: 1\n            successThreshold: 1\n        \
    \    failureThreshold: 3\n      dnsPolicy: Default\n      volumes:\n        -\
    \ name: config-volume\n          configMap:\n            name: coredns\n     \
    \       items:\n              - key: Corefile\n                path: Corefile\n\
    \              - key: NodeHosts\n                path: NodeHosts\n        - name:\
    \ custom-config-volume\n          configMap:\n            name: coredns-custom\n\
    \            optional: true\n---\napiVersion: v1\nkind: Service\nmetadata:\n \
    \ name: kube-dns\n  namespace: kube-system\n  annotations:\n    prometheus.io/port:\
    \ \"9153\"\n    prometheus.io/scrape: \"true\"\n  labels:\n    k8s-app: kube-dns\n\
    \    kubernetes.io/cluster-service: \"true\"\n    kubernetes.io/name: \"CoreDNS\"\
    \nspec:\n  selector:\n    k8s-app: kube-dns\n  type: ClusterIP\n  ports:\n   \
    \ - name: dns\n      port: 53\n      targetPort: 1053\n      protocol: UDP\n \
    \   - name: dns-tcp\n      port: 53\n      targetPort: 1053\n      protocol: TCP\n\
    \    - name: metrics\n      port: 9153\n      protocol: TCP\n"
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    name: vc-oidc-coredns
  name: vc-oidc-coredns
  namespace: testns
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-production
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  rules:
    - host: testcluster.local
      http:
        paths:
          - backend:
              service:
                name: oidc
                port:
                  name: https
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - testcluster.local
      secretName: oidc-tls
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PostSync
  labels:
    name: oidc-synthesize
  name: oidc-synthesize
  namespace: testns
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        name: oidc-synthesize
    spec:
      containers:
        - args:
            - -eu
            - -c
            - "#!/bin/sh\nset -eu\n\ncp /etc/vcluster-kubeconfig/config ./config\n\
              vcluster_kubeconfig=./config\n\necho \"Setting server URL...\"\n\nkubectl\
              \ --kubeconfig \"$vcluster_kubeconfig\" config set clusters.local.server\
              \ \"$VCLUSTER_SERVER_URL\"\n\necho \"Checking for namespace 'syn'...\"\
              \n\nexists=$(kubectl --kubeconfig \"$vcluster_kubeconfig\" get namespace\
              \ syn --ignore-not-found)\nif [ -n \"$exists\" ]; then\n  echo \"Namespace\
              \ 'syn' exists. Skipping synthesize.\"\n  exit 0\nfi\n\necho \"Starting\
              \ synthesize...\"\n\nkubectl --kubeconfig \"$vcluster_kubeconfig\" apply\
              \ -f \"$1\"\n\necho \"Done!\"\n"
            - --
            - https://syn.example.com/steward/install.json?token=w84kxjbhf
          command:
            - sh
          env:
            - name: HOME
              value: /export
            - name: VCLUSTER_SERVER_URL
              value: https://oidc:443
          image: docker.io/bitnami/kubectl:1.25.5
          imagePullPolicy: IfNotPresent
          name: oidc-synthesize
          ports: []
          stdin: false
          tty: false
          volumeMounts:
            - mountPath: /export
              name: export
            - mountPath: /etc/vcluster-kubeconfig
              name: kubeconfig
              readOnly: true
          workingDir: /export
      imagePullSecrets: []
      initContainers: []
      restartPolicy: OnFailure
      terminationGracePeriodSeconds: 30
      volumes:
        - emptyDir: {}
          name: export
        - name: kubeconfig
          secret:
            secretName: vc-oidc-kubeconfig
