apiVersion: v1
kind: ServiceAccount
metadata:
  annotations: {}
  labels:
    name: vc-oidc
  name: vc-oidc
  namespace: testns
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
rules:
  - apiGroups:
      - ''
    resources:
      - configmaps
      - secrets
      - services
      - pods
      - pods/attach
      - pods/portforward
      - pods/exec
      - endpoints
      - persistentvolumeclaims
    verbs:
      - create
      - delete
      - patch
      - update
      - get
      - list
      - watch
  - apiGroups:
      - ''
    resources:
      - events
      - pods/log
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - create
      - delete
      - patch
      - update
      - get
      - list
      - watch
  - apiGroups:
      - apps
    resources:
      - statefulsets
      - replicasets
      - deployments
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: oidc
subjects:
  - kind: ServiceAccount
    name: vc-oidc
    namespace: testns
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations: {}
  labels:
    name: syn-vcluster-oidc
  name: syn-vcluster-oidc
rules:
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations: {}
  labels:
    name: syn-vcluster-oidc
  name: syn-vcluster-oidc
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: syn-vcluster-oidc
subjects:
  - kind: ServiceAccount
    name: vc-oidc
    namespace: testns
---
apiVersion: v1
kind: Service
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
  selector:
    app: vcluster
    release: oidc
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  annotations: {}
  labels:
    name: oidc-headless
  name: oidc-headless
  namespace: testns
spec:
  clusterIP: None
  ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
  selector:
    app: vcluster
    release: oidc
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations: {}
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vcluster
      release: oidc
  serviceName: oidc-headless
  template:
    metadata:
      labels:
        app: vcluster
        release: oidc
    spec:
      affinity: {}
      containers:
        - args:
            - server
            - --write-kubeconfig=/data/k3s-config/kube-config.yaml
            - --data-dir=/data
            - --disable=traefik,servicelb,metrics-server,local-storage,coredns
            - --disable-network-policy
            - --disable-agent
            - --disable-scheduler
            - --disable-cloud-controller
            - --flannel-backend=none
            - --service-cidr=172.30.0.0/16
            - --kube-controller-manager-arg=controllers=*,-nodeipam,-nodelifecycle,-persistentvolume-binder,-attachdetach,-persistentvolume-expander,-cloud-node-lifecycle
            - --tls-san=oidc.testns.svc.cluster.local
            - --tls-san=oidc.testns.svc
            - --tls-san=oidc.testns
            - --tls-san=oidc
            - --kube-apiserver-arg=oidc-issuer-url=https://id.local/auth/realms/local
            - --kube-apiserver-arg=oidc-client-id=local
            - --kube-apiserver-arg=oidc-username-claim=email
            - --kube-apiserver-arg=oidc-groups-claim=groups
          command:
            - /bin/k3s
          env: []
          image: docker.io/rancher/k3s:v1.25.4-k3s1
          name: vcluster
          resources:
            limits:
              memory: 2Gi
            requests:
              cpu: 200m
              memory: 256Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
            - mountPath: /data
              name: data
            - mountPath: /etc/rancher
              name: etc-rancher
        - args:
            - --name=oidc
            - --out-kube-config-secret=vc-oidc-kubeconfig
            - --sync=ingresses
            - --tls-san=oidc.testns.svc.cluster.local
            - --tls-san=oidc.testns.svc
            - --tls-san=oidc.testns
            - --tls-san=oidc
          env:
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          image: docker.io/loftsh/vcluster:0.14.2
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /healthz
              port: 8443
              scheme: HTTPS
            initialDelaySeconds: 60
            periodSeconds: 2
          name: syncer
          readinessProbe:
            failureThreshold: 30
            httpGet:
              path: /readyz
              port: 8443
              scheme: HTTPS
            periodSeconds: 2
          resources:
            limits:
              memory: 1Gi
            requests:
              cpu: 100m
              memory: 128Mi
          securityContext:
            allowPrivilegeEscalation: false
          volumeMounts:
            - mountPath: /data
              name: data
              readOnly: true
            - mountPath: /manifests/coredns
              name: coredns
              readOnly: true
      nodeSelector: {}
      serviceAccountName: vc-oidc
      terminationGracePeriodSeconds: 10
      tolerations: []
      volumes:
        - configMap:
            defaultMode: 420
            name: vc-oidc-coredns
          name: coredns
        - emptyDir: {}
          name: etc-rancher
        - emptyDir: {}
          name: data
  volumeClaimTemplates: []
---
apiVersion: v1
data:
  manifests: |
    ---
    "apiVersion": "rbac.authorization.k8s.io/v1"
    "kind": "ClusterRoleBinding"
    "metadata":
      "name": "oidc-cluster-admin"
    "roleRef":
      "apiGroup": "rbac.authorization.k8s.io"
      "kind": "ClusterRole"
      "name": "cluster-admin"
    "subjects":
    - "kind": "Group"
      "name": "admin"
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    name: oidc-init-manifests
  name: oidc-init-manifests
  namespace: testns
---
apiVersion: v1
data:
  coredns.yaml: |
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: coredns
      namespace: kube-system
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      labels:
        kubernetes.io/bootstrapping: rbac-defaults
      name: system:coredns
    rules:
      - apiGroups:
          - ""
        resources:
          - endpoints
          - services
          - pods
          - namespaces
        verbs:
          - list
          - watch
      - apiGroups:
          - discovery.k8s.io
        resources:
          - endpointslices
        verbs:
          - list
          - watch
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      annotations:
        rbac.authorization.kubernetes.io/autoupdate: "true"
      labels:
        kubernetes.io/bootstrapping: rbac-defaults
      name: system:coredns
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: system:coredns
    subjects:
      - kind: ServiceAccount
        name: coredns
        namespace: kube-system
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: coredns
      namespace: kube-system
    data:
      Corefile: |
        .:1053 {
            {{.LOG_IN_DEBUG}}
            errors
            health
            ready
            kubernetes cluster.local in-addr.arpa ip6.arpa {
              pods insecure
              fallthrough in-addr.arpa ip6.arpa
            }
            hosts /etc/coredns/NodeHosts {
              ttl 60
              reload 15s
              fallthrough
            }
            prometheus :9153
            forward . /etc/resolv.conf
            cache 30
            loop
            reload
            loadbalance
        }

        import /etc/coredns/custom/*.server
      NodeHosts: ""
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: coredns
      namespace: kube-system
      labels:
        k8s-app: kube-dns
        kubernetes.io/name: "CoreDNS"
    spec:
      replicas: 1
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxUnavailable: 1
      selector:
        matchLabels:
          k8s-app: kube-dns
      template:
        metadata:
          labels:
            k8s-app: kube-dns
        spec:
          priorityClassName: "system-cluster-critical"
          serviceAccountName: coredns
          nodeSelector:
            kubernetes.io/os: linux
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  k8s-app: kube-dns
          containers:
            - name: coredns
              image: {{.IMAGE}}
              imagePullPolicy: IfNotPresent
              resources:
                limits:
                  cpu: 1000m
                  memory: 170Mi
                requests:
                  cpu: 100m
                  memory: 70Mi
              args: [ "-conf", "/etc/coredns/Corefile" ]
              volumeMounts:
                - name: config-volume
                  mountPath: /etc/coredns
                  readOnly: true
                - name: custom-config-volume
                  mountPath: /etc/coredns/custom
                  readOnly: true
              ports:
                - containerPort: 1053
                  name: dns
                  protocol: UDP
                - containerPort: 1053
                  name: dns-tcp
                  protocol: TCP
                - containerPort: 9153
                  name: metrics
                  protocol: TCP
              securityContext:
                runAsUser: {{.RUN_AS_USER}}
                runAsNonRoot: {{.RUN_AS_NON_ROOT}}
                allowPrivilegeEscalation: false
                capabilities:
                  drop:
                    - ALL
                readOnlyRootFilesystem: true
              livenessProbe:
                httpGet:
                  path: /health
                  port: 8080
                  scheme: HTTP
                initialDelaySeconds: 60
                periodSeconds: 10
                timeoutSeconds: 1
                successThreshold: 1
                failureThreshold: 3
              readinessProbe:
                httpGet:
                  path: /ready
                  port: 8181
                  scheme: HTTP
                initialDelaySeconds: 0
                periodSeconds: 2
                timeoutSeconds: 1
                successThreshold: 1
                failureThreshold: 3
          dnsPolicy: Default
          volumes:
            - name: config-volume
              configMap:
                name: coredns
                items:
                  - key: Corefile
                    path: Corefile
                  - key: NodeHosts
                    path: NodeHosts
            - name: custom-config-volume
              configMap:
                name: coredns-custom
                optional: true
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: kube-dns
      namespace: kube-system
      annotations:
        prometheus.io/port: "9153"
        prometheus.io/scrape: "true"
      labels:
        k8s-app: kube-dns
        kubernetes.io/cluster-service: "true"
        kubernetes.io/name: "CoreDNS"
    spec:
      selector:
        k8s-app: kube-dns
      type: ClusterIP
      ports:
        - name: dns
          port: 53
          targetPort: 1053
          protocol: UDP
        - name: dns-tcp
          port: 53
          targetPort: 1053
          protocol: TCP
        - name: metrics
          port: 9153
          protocol: TCP
kind: ConfigMap
metadata:
  annotations: {}
  labels:
    name: vc-oidc-coredns
  name: vc-oidc-coredns
  namespace: testns
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-production
  labels:
    name: oidc
  name: oidc
  namespace: testns
spec:
  rules:
    - host: testcluster.local
      http:
        paths:
          - backend:
              service:
                name: oidc
                port:
                  name: https
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - testcluster.local
      secretName: oidc-tls
---
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    argocd.argoproj.io/hook: PostSync
  labels:
    name: oidc-synthesize
  name: oidc-synthesize
  namespace: testns
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      labels:
        name: oidc-synthesize
    spec:
      containers:
        - args:
            - -eu
            - -c
            - |
              #!/bin/sh
              set -eu

              cp /etc/vcluster-kubeconfig/config ./config
              vcluster_kubeconfig=./config

              echo "Setting server URL..."

              kubectl --kubeconfig "$vcluster_kubeconfig" config set clusters.local.server "$VCLUSTER_SERVER_URL"

              echo "Checking for namespace 'syn'..."

              exists=$(kubectl --kubeconfig "$vcluster_kubeconfig" get namespace syn --ignore-not-found)
              if [ -n "$exists" ]; then
                echo "Namespace 'syn' exists. Skipping synthesize."
                exit 0
              fi

              echo "Starting synthesize..."

              kubectl --kubeconfig "$vcluster_kubeconfig" apply -f "$1"

              echo "Done!"
            - --
            - https://syn.example.com/steward/install.json?token=w84kxjbhf
          command:
            - sh
          env:
            - name: HOME
              value: /export
            - name: VCLUSTER_SERVER_URL
              value: https://oidc:443
          image: docker.io/bitnami/kubectl:1.26.3
          imagePullPolicy: IfNotPresent
          name: oidc-synthesize
          ports: []
          stdin: false
          tty: false
          volumeMounts:
            - mountPath: /export
              name: export
            - mountPath: /etc/vcluster-kubeconfig
              name: kubeconfig
              readOnly: true
          workingDir: /export
      imagePullSecrets: []
      initContainers: []
      restartPolicy: OnFailure
      terminationGracePeriodSeconds: 30
      volumes:
        - emptyDir: {}
          name: export
        - name: kubeconfig
          secret:
            secretName: vc-oidc-kubeconfig
